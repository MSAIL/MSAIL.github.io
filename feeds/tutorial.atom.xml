<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>MSAIL</title><link href="http://msail.org/" rel="alternate"></link><link href="http://msail.org/feeds/tutorial.atom.xml" rel="self"></link><id>http://msail.org/</id><updated>2016-01-19T17:30:00-05:00</updated><entry><title>K-Means Clustering</title><link href="http://msail.org/events/tutorial/2016/Jan/19/k-means-clustering" rel="alternate"></link><updated>2016-01-19T17:30:00-05:00</updated><author><name>MSAIL</name></author><id>tag:msail.org,2016-01-19:events/tutorial/2016/Jan/19/k-means-clustering</id><summary type="html">&lt;p&gt;The problem is computationally difficult (NP-hard); however, there are efficient heuristic algorithms that are commonly employed and converge quickly to a local optimum. These are usually similar to the expectation-maximization algorithm for mixtures of Gaussian distributions via an iterative refinement approach employed by both algorithms. Additionally, they both use cluster centers to model the data; however, k-means clustering tends to find clusters of comparable spatial extent, while the expectation-maximization mechanism allows clusters to have different shapes.&lt;/p&gt;</summary></entry></feed>