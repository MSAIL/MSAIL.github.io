<!DOCTYPE html>

<html>
    <head>
        <!-- Metadata -->
    	<meta charset="utf-8">
    
        <!-- Title -->
        <title>MSAIL</title>
    
        <!-- Google Fonts -->
        <link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,700italic,400italic,600,600italic' rel='stylesheet' type='text/css'>
    
        <!-- CSS -->
        <link rel="stylesheet" href="theme/css/style.css" type="text/css">
    </head>
    
    <body>
    	<!-- Page Header -->
        <div id="page-header"><div id="header-center"><div id="header-content">
            <!-- Logo -->
    		<a id="header-logo" href="index.html">
    			<img src="http://msail.github.io/theme/images/msail-logo-head.png">
    		</a>
    		<!-- Header Text -->
            <div id="header-text"><div>
                <a id="header-title" href="index.html">
                    Michigan Student Artificial Intelligence Lab
                </a>
                <ul id="header-nav">
    					<li><a href="activities.html">
    						Activities
    					</a></li>
                                        <!--
    					<li><a href="blog.html">
    					    Blog
    					</a></li>
                                        -->
    					<li><a href="resources.html">
    						Resources
    					</a></li>
                </ul>
            </div></div>
        </div></div></div>
    
    	<!-- Page Body -->
    	<div id="page-wrap">
    		<!-- Page Content -->
    	    <div id="page-content">
                <p>
                    The <b>Michigan Student Artificial Intelligence Lab (MSAIL)</b>
                    is a student organization for discussion of artificial intelligence
                    and machine learning.
                    <a href="http://www.huffingtonpost.com/2015/05/13/andrew-ng_n_7267682.html">Andrew Ng said</a>:
    
                    <blockquote>
                        <span class="quote">&ldquo;</span>
                        ...if you read research papers consistently, if you seriously study
                        half a dozen papers a week and you do that for two years, after
                        those two years you will have learned a lot... But that sort of
                        investment, if you spend a whole Saturday studying rather than
                        watching TV, there's no one there to pat you on the back or tell
                        you you did a good job.
                        <span class="quote">&rdquo;</span> &emsp;&mdash;&nbsp; Andrew Ng
                    </blockquote>
                    
                    MSAIL is a community in which motivated students can read
                    and discuss modern machine learning literature together. 
                    We welcome students of all backgrounds and ability.  To join
                    MSAIL and stay up to date, simply join our  
                    <a href="https://msail-team.slack.com/signup">Slack team</a>!

                    Also be sure to check out our sister organization: the
                    <a href="https://www.mdst.club/">Michigan Data Science Team</a>! 
                    We are both graciously sponsored by the <a href="http://midas.umich.edu/">Michigan Institute for Data Science</a>.
                </p>

                <!-- Upcoming Events -->
                <h1>Upcoming Events</h1>

                <div class="event-list">
                    <div class="event-panel">
                        <!-- Event Side -->
                        <div class="event-side-rg">
                            <div class="fancy-date">
                                <div class="fancy-dayofweek">
                                    WED
                                </div>
                                <div class="fancy-monthday">
                                    Feb 26
                                </div>
                            </div>
                            <div class="event-icon-rg"></div>
                        </div>

                        <!-- Event Main -->
                        <div class="event-main">
                            <div class="event-header">
                                <!-- Title -->
                                <div class="event-title">
                                    <span class="event-type">Reading Group</span>
                                    <span class="event-name"><a href ="https://www.openmined.org" target="_blank">Privacy Preserving Machine Learning</a></span>
                                </div>
                                <!-- Info -->
                                <div class="event-info">
                                    Wednesday (2020-2-26) at 18:30 in BBB 3725
                                </div>
                            </div>
                                <div class="event-body">
                                    <p>
                                        Privacy preserving machine learning is a technique that is being developed to 
                                        train machine learning models on data that is decentralized and kept private to 
                                        the model creator. We strive to keep the training data, inputs and outputs to the 
                                        model, and the model parameters themselves visible only to their owners. Data privacy 
                                        is one of the important problems of the next decade and is becoming extremely important 
                                        to building trust between AI agents and people. We will discuss the various technical 
                                        concepts that are necessary for a fully privacy preserving machine learning system: 
                                        homomorphic encryption, multi-party computation, federated learning, and differential privacy.
                                    </p>
                                </div>
                            </div>
                        </div>
                    </div>
                
                <!-- Recent Events -->
                <h1>Recent Events</h1>
                    <div class="event-panel">
                        <!-- Event Side -->
                        <div class="event-side-rg">
                            <div class="fancy-date">
                                <div class="fancy-dayofweek">
                                    WED
                                </div>
                                <div class="fancy-monthday">
                                    Feb 19
                                </div>
                            </div>
                            <div class="event-icon-rg"></div>
                        </div>

                        <!-- Event Main -->
                        <div class="event-main">
                            <div class="event-header">
                                <!-- Title -->
                                <div class="event-title">
                                    <span class="event-type">Reading Group</span>
                                    <span class="event-name"><a href ="https://arxiv.org/pdf/1906.07241.pdf" target="_blank">Training Language Models with Knowledge Bases</a></span>
                                </div>
                                <!-- Info -->
                                <div class="event-info">
                                    Wednesday (2020-2-19) at 18:30 in BBB 3725
                                </div>
                            </div>
                                <div class="event-body">
                                    <p>
                                        Language Modelling refers to the task of constructing a probability distribution 
                                        over a sequence of words, enabling models to generate text, and predict the next 
                                        word in a sequence. Since Language Models learn from unlabeled text corpora, they 
                                        have the capability to train, unsupervised, on massive quantities of textual data. 
                                        However, the real magic of language modelling is in using embeddings from pretrained 
                                        language models for downstream transfer learning applications, such as question answering, 
                                        and textual classification. Large scale language models such as BERT, XLnet, and GPT-2 have 
                                        been shown to outperform almost other models on almost every NLP task, and this insight 
                                        is being referred to as the “ImageNet moment” for NLP. However, although Language models 
                                        are tremendously powerful in encoding semantic information, they have limited capability 
                                        to encode “knowledge” about the real world. This paper explores the possibility of 
                                        bootstrapping “knowledge” to language models, in order to generate text which is not 
                                        only semantically/grammatically correct but also factually accurate.
                                    </p>
                                </div>
                            </div>
                    </div>
                    <div class="event-panel">
                        <!-- Event Side -->
                        <div class="event-side-rg">
                            <div class="fancy-date">
                                <div class="fancy-dayofweek">
                                    WED
                                </div>
                                <div class="fancy-monthday">
                                    Feb 12
                                </div>
                            </div>
                            <div class="event-icon-rg"></div>
                        </div>

                        <!-- Event Main -->
                        <div class="event-main">
                            <div class="event-header">
                                <!-- Title -->
                                <div class="event-title">
                                    <span class="event-type">Reading Group</span>
                                    <span class="event-name"><a href ="https://arxiv.org/abs/1902.09811" target="_blank">Label-Set Operations Networks</a></span>
                                </div>
                                <!-- Info -->
                                <div class="event-info">
                                    Wednesday (2020-2-12) at 18:30 in BBB 3725
                                </div>
                            </div>
                                <div class="event-body">
                                    <p>
                                        Image classification models have become quite good at predicting what is in a given image. 
                                        In fact, many models even outperform reported human classification performance on the ImageNet dataset. 
                                        But can models generalize to unseen labels? If we only train on images of dogs and dogs with bones, 
                                        can we correctly classify an image of just a bone? Label-Set Operations attempt to do this by learning a 
                                        feature space and set operations functions that can perform the intersection, union, and difference of 
                                        label sets. This is useful for automatically generating data for unseen labels that will help a model 
                                        generalize better.
                                    </p>
                                </div>
                            </div>
                    </div>
                    <div class="event-panel">
                        <!-- Event Side -->
                        <div class="event-side-rg">
                            <div class="fancy-date">
                                <div class="fancy-dayofweek">
                                    WED
                                </div>
                                <div class="fancy-monthday">
                                    Feb 06
                                </div>
                            </div>
                            <div class="event-icon-rg"></div>
                        </div>
                
                        <!-- Event Main -->
                        <div class="event-main">
                            <div class="event-header">
                                <!-- Title -->
                                <div class="event-title">
                                    <span class="event-type">Reading Group</span>
                                    <span class="event-name"><a href ="https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf" target="_blank">Deep Q-learning</a></span>
                                </div>
                
                                <!-- Info -->
                                <div class="event-info">
                                    Wednesday (2020-2-06) at 18:30 in BBB 3725
                                </div>
                            </div>
                
                            <div class="event-body">
                                <p>
                                    Most of the learning mechanisms we have discussed in MSAIL fall into two categories: supervised or unsupervised.
                                    In a sense, we either learn from feeding in data to models and telling them what the correct output should be or we 
                                    attempt to recognize patterns inherent to the data presented to us to make a prediction. 
                                    Reinforcement learning is a third category on its own and Q-learning is an implementation that falls into that category. 
                                    The general premise is that we put a model in an open environment with a constrained set of actions it can take and attempt 
                                    to learn a function that will predict the long-term value of each action taken. It does this by experimenting in 
                                    the environment over and over again, until it can discern meaningful patterns. Deep Q-learning is an attempt to l
                                    earn this value function through a neural architecture. This week we discusssed this topic of Deep Q-learning, and furthermore how 
                                    it can be used to solve difficult problems, like training a model to play Mariro.
                                </p>
                            </div>
                        </div>
                    </div>
                </div>
    
                <!-- Leadership -->
                <h1>Active Leadership</h1>
                
                The following awesome people plan MSAIL's activities.  If you
                would like to help out as well, contact Sean via email.  
                Our <a href="constitution.html">constitution</a> codifies our
                roles. 
                <div id="leadership">
                    <!-- Laura Balzano -->
                    <div class="leader-box">
                        <div class="leader-portrait">
                            <img src="theme/images/leadership/laura.jpg">
                        </div>
                        <div class="leader-name">Laura Balzano </div>
                        <div class="leader-info"> Assistant Professor in EECS </div>
                        <div class="leader-info"> Faculty Mentor </div>
                    </div>
                    
                    <!-- Nikhil Devraj -->
                    <div class="leader-box">
                        <div class="leader-portrait">
                            <img src="theme/images/leadership/nikhil.jpeg">
                        </div>
                        <div class="leader-name"> Nikhil Devraj </div>
                        <div class="leader-info"> BS '21 Computer Science </div>
                        <div class="leader-info"> Speakers  </div>
                    </div>

                   <!-- Yash Gambhir -->
                    <div class="leader-box">
                        <div class="leader-portrait">
                            <img src="theme/images/leadership/yash.jpeg">
                        </div>
                        <div class="leader-name"> Yashmeet Gambhir </div>
                        <div class="leader-info"> BS '19, Computer Science </div>
                        <div class="leader-info"> Tutorials &amp Projects </div>
                    </div>

                    <!-- Danai Koutra -->
                    <div class="leader-box">
                        <div class="leader-portrait">
                            <img src="theme/images/leadership/danai.jpg">
                        </div>
                        <div class="leader-name"> Danai Koutra </div>
                        <div class="leader-info"> Assistant Professor in CSE </div>
                        <div class="leader-info"> Faculty Mentor </div>
                    </div>

                    <!-- Patrick Morgan -->
                    <div class="leader-box">
                        <div class="leader-portrait">
                            <img src="theme/images/leadership/pmorg.jpeg">
                        </div>
                        <div class="leader-name"> Patrick Morgan </div>
                        <div class="leader-info"> BS '22 Computer Science </div>
                        <div class="leader-info"> Administrivia </div>
                    </div>

                    <!-- Sean Stapleton -->
                    <div class="leader-box">
                        <div class="leader-portrait">
                            <img src="theme/images/leadership/sean.jpeg">
                        </div>
                        <div class="leader-name"> Sean Stapleton </div>
                        <div class="leader-info"> BS '20, Computer Science </div>
                        <div class="leader-info"> Administrivia </div>
                    </div>

                    <!-- Jenna Wiens -->
                    <div class="leader-box">
                        <div class="leader-portrait">
                            <img src="theme/images/leadership/jenna.png">
                        </div>
                        <div class="leader-name"> Jenna Wiens </div>
                        <div class="leader-info"> Assistant Professor in CSE </div>
                        <div class="leader-info"> Faculty Mentor </div>
                    </div>

                </div>
        	</div>
    
    	    <!-- Page Footer -->
    	    <div id="page-footer">
    			<span style="float: left">
    				Last updated on 2020-2-19
    			</span>
    	    </div>
    	</div>
    </body>
</html>
