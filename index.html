<!DOCTYPE html>

<html>
    <head>
        <!-- Metadata -->
    	<meta charset="utf-8">
    
        <!-- Title -->
        <title>MSAIL</title>
    
        <!-- Google Fonts -->
        <link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,700italic,400italic,600,600italic' rel='stylesheet' type='text/css'>
    
        <!-- CSS -->
        <link rel="stylesheet" href="theme/css/style.css" type="text/css">
    </head>
    
    <body>
    	<!-- Page Header -->
        <div id="page-header"><div id="header-center"><div id="header-content">
            <!-- Logo -->
    		<a id="header-logo" href="index.html">
    			<img src="http://msail.github.io/theme/images/msail-logo-head.png">
    		</a>
    		<!-- Header Text -->
            <div id="header-text"><div>
                <a id="header-title" href="index.html">
                    Michigan Student Artificial Intelligence Lab
                </a>
                <ul id="header-nav">
    					<li><a href="activities.html">
    						Activities
    					</a></li>
                                        <!--
    					<li><a href="blog.html">
    					    Blog
    					</a></li>
                                        -->
    					<li><a href="resources.html">
    						Resources
    					</a></li>
                </ul>
            </div></div>
        </div></div></div>
    
    	<!-- Page Body -->
    	<div id="page-wrap">
    		<!-- Page Content -->
    	    <div id="page-content">
                <p>
                    The <b>Michigan Student Artificial Intelligence Lab (MSAIL)</b>
                    is a student organization for discussion of artificial intelligence
                    and machine learning.
                    <a href="http://www.huffingtonpost.com/2015/05/13/andrew-ng_n_7267682.html">Andrew Ng said</a>:
    
                    <blockquote>
                        <span class="quote">&ldquo;</span>
                        ...if you read research papers consistently, if you seriously study
                        half a dozen papers a week and you do that for two years, after
                        those two years you will have learned a lot... But that sort of
                        investment, if you spend a whole Saturday studying rather than
                        watching TV, there's no one there to pat you on the back or tell
                        you you did a good job.
                        <span class="quote">&rdquo;</span> &emsp;&mdash;&nbsp; Andrew Ng
                    </blockquote>
                    
                    MSAIL is a community in which motivated students can read
                    and discuss modern machine learning literature together. 
                    We welcome students of all backgrounds and ability.  To join
                    MSAIL and stay up to date, simply join our  
                    <a href="https://join.slack.com/t/msail-team/shared_invite/enQtMjUwMzc4NzUxMTQwLWVjMGMyMDMyYjFmOTgyZjU4MjlhZmQzODE0MzEyNjBmYWRiM2E3ZGQwZWZhNDM1N2E2YWVkMjIxMGI3ZjBiZTk">Slack team</a>!

                    Also be sure to check out our sister organization: the
                    <a href="https://www.mdst.club/">Michigan Data Science Team</a>! 
                    We are both graciously sponsored by the <a href="http://midas.umich.edu/">Michigan Institute for Data Science</a>.
                </p>
    
                <!-- Upcoming Events -->
                <h1>Upcoming Events</h1>
                
                <div class="event-list">
                    <div class="event-panel">
                        <!-- Event Side -->
                        <div class="event-side-rg">
                            <div class="fancy-date">
                                <div class="fancy-dayofweek">
                                    TUE
                                </div>
                                <div class="fancy-monthday">
                                    Oct 08
                                </div>
                            </div>
                            <div class="event-icon-rg"></div>
                        </div>
                
                        <!-- Event Main -->
                        <div class="event-main">
                            <div class="event-header">
                                <!-- Title -->
                                <div class="event-title">
                                    <span class="event-type">Reading Group</span>
                                    <span class="event-name">
                                        <a href="http://langcog.stanford.edu/papers_new/goodman-2016-tics.pdf">
                                        Pragmatic Language Interpretation</a>
                                    </span>
                                </div>
                
                                <!-- Info -->
                                <div class="event-info">
                                    Tuesday (2019-10-08) at 18:00 in BBB 3725
                                </div>
                            </div>
                
                            <div class="event-body">
                                <p>
                                    Traditional NLP models view language as a set of fixed conventions.
                                    Pragmatics is the study of how language is used for communicative purposes.
                                    We explore the rational speech act (RSA) model, which is a probabilistic model
                                    that formalizes many intuitive aspects of language and enables us to predict
                                    human behavior.
                                </p>
                            </div>
                        </div>
                    </div>
                </div>
                
                <!-- Recent Events -->
                <h1>Recent Events</h1>
                    <div class="event-panel">
                        <!-- Event Side -->
                        <div class="event-side-rg">
                            <div class="fancy-date">
                                <div class="fancy-dayofweek">
                                    TUE
                                </div>
                                <div class="fancy-monthday">
                                    Oct 01
                                </div>
                            </div>
                            <div class="event-icon-rg"></div>
                        </div>
                
                        <!-- Event Main -->
                        <div class="event-main">
                            <div class="event-header">
                                <!-- Title -->
                                <div class="event-title">
                                    <span class="event-type">Reading Group</span>
                                    <span class="event-name">Neural Machine Translation</span>
                                </div>
                
                                <!-- Info -->
                                <div class="event-info">
                                    Tuesday (2019-10-01) at 18:00 in BBB 3725
                                </div>
                            </div>
                
                            <div class="event-body">
                                <p>
                                    Neural networks are dense, parametric, and continuous, while language is sparse,
                                    non-parametric, and discrete. So how can the former process the latter?

                                    Famously, one uses one-hot embeddings and softmax sampling to translate between
                                    continuous and discrete domains. One uses word embeddings to represent sparse sets
                                    of words as dense clouds of semantic vectors. One use recurrent neural networks to
                                    reduce variable-length sequence problems to local, parametric ones.
                                    
                                    But there has been another breakthrough recently: one can use Attention Mechanisms
                                    to model long-distance relationships between words! Attention lies at the core of
                                    this week's papers.
                                </p>
                            </div>
                        </div>
                    </div>

                    <div class="event-panel">
                        <!-- Event Side -->
                        <div class="event-side-rg">
                            <div class="fancy-date">
                                <div class="fancy-dayofweek">
                                    TUE
                                </div>
                                <div class="fancy-monthday">
                                    Sep 24
                                </div>
                            </div>
                            <div class="event-icon-rg"></div>
                        </div>

                        <!-- Event Main -->
                        <div class="event-main">
                            <div class="event-header">
                                <!-- Title -->
                                <div class="event-title">
                                    <span class="event-type">Reading Group</span>
                                    <span class="event-name">Generative Adversarial Networks</span>
                                </div>
                
                                <!-- Info -->
                                <div class="event-info">
                                    Tuesday (2019-09-24) at 18:00 in BBB 3725
                                </div>
                            </div>
                
                            <div class="event-body">
                                <p>
                                    Discriminative models have several key limitations, namely they cannot model the
                                    probability of seeing a given input example and therefore cannot generate new examples.

                                    Generative Adversarial Networks (GANs) are an application of generative models in which a generator and discriminator are trained
                                    to compete against one another in a 2-person game. The generator attempts to create samples
                                    that deceive the discriminator into believing they are true samples, and the discriminator attempts
                                    to determine which samples are real and generated.

                                    We explore the motivation behind GANs, basic theory of how they work, and dive into the future of
                                    generative models.
                                </p>
                            </div>
                        </div>
                    </div>

                    <div class="event-panel">
                        <!-- Event Side -->
                        <div class="event-side-rg">
                            <div class="fancy-date">
                                <div class="fancy-dayofweek">
                                    TUE
                                </div>
                                <div class="fancy-monthday">
                                    Sep 17
                                </div>
                            </div>
                            <div class="event-icon-rg"></div>
                        </div>

                        <!-- Event Main -->
                        <div class="event-main">
                            <div class="event-header">
                                <!-- Title -->
                                <div class="event-title">
                                    <span class="event-type">Reading Group</span>
                                    <span class="event-name"><a href="https://arxiv.org/abs/1904.01766">
                                        VideoBERT: a Joint Model for Video and Language Learning
                                    </a></span>
                                </div>
                
                                <!-- Info -->
                                <div class="event-info">
                                    Tuesday (2019-09-17) at 18:00 in BBB 3725
                                </div>
                            </div>
                
                            <div class="event-body">
                                <p>
                                    Self-supervised learning has been a key data source for many recent state-of-the-art 
                                    natural language processing models. We explore a new use case for self-supervised learning
                                    with VideoBERT, an attempt to jointly train a visual-linguistic model to learn high-level
                                    features without any explicit supervision.
                                </p>
                            </div>
                        </div>
                    </div>

                
                </div>
    
                <!-- Leadership -->
                <h1>Active Leadership</h1>
                
                The following awesome people plan MSAIL's activities.  If you
                would like to help out as well, contact Sean via email.  
                Our <a href="constitution.html">constitution</a> codifies our
                roles. 
                <div id="leadership">
                    <!-- Laura Balzano -->
                    <div class="leader-box">
                        <div class="leader-portrait">
                            <img src="theme/images/leadership/laura.jpg">
                        </div>
                        <div class="leader-name">Laura Balzano </div>
                        <div class="leader-info"> Assistant Professor in EECS </div>
                        <div class="leader-info"> Faculty Mentor </div>
                    </div>
                    
                    <!-- Nikhil Devraj -->
                    <div class="leader-box">
                        <div class="leader-portrait">
                            <img src="theme/images/leadership/nikhil.jpeg">
                        </div>
                        <div class="leader-name"> Nikhil Devraj </div>
                        <div class="leader-info"> BS '21 Computer Science </div>
                        <div class="leader-info"> Speakers  </div>
                    </div>

                   <!-- Yash Gambhir -->
                    <div class="leader-box">
                        <div class="leader-portrait">
                            <img src="theme/images/leadership/yash.jpeg">
                        </div>
                        <div class="leader-name"> Yashmeet Gambhir </div>
                        <div class="leader-info"> BS '19, Computer Science </div>
                        <div class="leader-info"> Tutorials &amp Projects </div>
                    </div>

                    <!-- Danai Koutra -->
                    <div class="leader-box">
                        <div class="leader-portrait">
                            <img src="theme/images/leadership/danai.jpg">
                        </div>
                        <div class="leader-name"> Danai Koutra </div>
                        <div class="leader-info"> Assistant Professor in CSE </div>
                        <div class="leader-info"> Faculty Mentor </div>
                    </div>

                    <!-- Patrick Morgan -->
                    <div class="leader-box">
                        <div class="leader-portrait">
                            <img src="theme/images/leadership/pmorg.jpeg">
                        </div>
                        <div class="leader-name"> Patrick Morgan </div>
                        <div class="leader-info"> BS '22 Computer Science </div>
                        <div class="leader-info"> Administrivia </div>
                    </div>

                    <!-- Zachary Papanastasopoulos -->
                    <div class="leader-box">
                        <div class="leader-portrait">
                            <img src="theme/images/leadership/zach.jpeg">
                        </div>
                        <div class="leader-name"> Zach Papanastasopoulos </div>
                        <div class="leader-info"> BS '21 Computer Science </div>
                        <div class="leader-info"> Tutorials &amp Projects </div>
                    </div>

                    <!-- Sean Stapleton -->
                    <div class="leader-box">
                        <div class="leader-portrait">
                            <img src="theme/images/leadership/sean.jpeg">
                        </div>
                        <div class="leader-name"> Sean Stapleton </div>
                        <div class="leader-info"> BS '20, Computer Science </div>
                        <div class="leader-info"> Administrivia </div>
                    </div>

                    <!-- Jenna Wiens -->
                    <div class="leader-box">
                        <div class="leader-portrait">
                            <img src="theme/images/leadership/jenna.png">
                        </div>
                        <div class="leader-name"> Jenna Wiens </div>
                        <div class="leader-info"> Assistant Professor in CSE </div>
                        <div class="leader-info"> Faculty Mentor </div>
                    </div>

                </div>
        	</div>
    
    	    <!-- Page Footer -->
    	    <div id="page-footer">
    			<span style="float: left">
    				Last updated on 2019-10-08
    			</span>
    	    </div>
    	</div>
    </body>
</html>
