<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Computer Vision | MSAIL</title>
    <link>https://MSAIL.github.io/tag/computer-vision/</link>
      <atom:link href="https://MSAIL.github.io/tag/computer-vision/index.xml" rel="self" type="application/rss+xml" />
    <description>Computer Vision</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Thu, 05 Nov 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://MSAIL.github.io/media/logo.png</url>
      <title>Computer Vision</title>
      <link>https://MSAIL.github.io/tag/computer-vision/</link>
    </image>
    
    <item>
      <title>Convolutional Neural Networks</title>
      <link>https://MSAIL.github.io/education/cnn/</link>
      <pubDate>Thu, 05 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://MSAIL.github.io/education/cnn/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Topic&lt;/strong&gt;: Convolutional Neural Networks&lt;br&gt;
&lt;strong&gt;Presenter&lt;/strong&gt;: Kevin Wang&lt;/p&gt;
&lt;p&gt;This lesson covered convolutional neural networks, which serve as the backbone for many modern-day deep learning applications. Most commonly, convolutional neural networks are used for vision tasks (although not exclusively).&lt;/p&gt;
&lt;h2 id=&#34;supplemental-resources&#34;&gt;Supplemental Resources&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://docs.google.com/presentation/d/1522OsXalZScvuUxXrOTbUZuISZUY-HqO&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides on CNNs&lt;/a&gt;&lt;br&gt;

&lt;a href=&#34;https://docs.google.com/presentation/d/16TMR2sM9T75qALw3CCigUF_JxMQ5gceM&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides on Neural Networks&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Brain-Inspired AI</title>
      <link>https://MSAIL.github.io/talk/brain_insp_110320/</link>
      <pubDate>Tue, 03 Nov 2020 18:00:00 -0400</pubDate>
      <guid>https://MSAIL.github.io/talk/brain_insp_110320/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Speaker(s)&lt;/strong&gt;: 
&lt;a href=&#34;https://johnmday.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;John Day&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Topic&lt;/strong&gt;: Brain-inspired AI&lt;/p&gt;
&lt;p&gt;John started his talk by discussing brain-inspired AI in general, which involves studies like 
&lt;a href=&#34;https://www.nature.com/articles/531S16a&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;neural modeling&lt;/a&gt;, 
&lt;a href=&#34;https://en.wikipedia.org/wiki/Artificial_consciousness#:~:text=Artificial%20consciousness%20%28AC%29%2C%20also,artificial%20intelligence%20and%20cognitive%20robotics.&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;artificial consciousness&lt;/a&gt;, 
&lt;a href=&#34;https://en.wikipedia.org/wiki/Spiking_neural_network&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;spiking neural nets&lt;/a&gt;, and 
&lt;a href=&#34;https://en.wikipedia.org/wiki/Cognitive_architecture&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;cognitive architectures&lt;/a&gt;. Afterwards, he focused on deep predictive coding networks.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://drive.google.com/file/d/1Gly--En531JIa4F_h15TWAftKrJPEd5W/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;You can find a recording of his talk here.&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;supplemental-resources&#34;&gt;Supplemental Resources&lt;/h3&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.cell.com/neuron/pdf/S0896-6273%2817%2930509-3.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Brain-inspired AI&lt;/a&gt;&lt;br&gt;

&lt;a href=&#34;http://klab.tch.harvard.edu/publications/PDFs/gk7591_Lotteretal_ICLR2017.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning&lt;/a&gt;&lt;br&gt;

&lt;a href=&#34;https://arxiv.org/pdf/1802.04762.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Deep Predictive Coding Network for Object Recognition&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Image-to-Image Translation with Conditional Adversarial Networks</title>
      <link>https://MSAIL.github.io/talk/cgan_102020/</link>
      <pubDate>Tue, 20 Oct 2020 18:00:00 -0400</pubDate>
      <guid>https://MSAIL.github.io/talk/cgan_102020/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Speaker(s)&lt;/strong&gt;: Andrew Awad&lt;br&gt;
&lt;strong&gt;Topic&lt;/strong&gt;: 
&lt;a href=&#34;https://arxiv.org/abs/1611.07004&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Image-to-Image Translation with Conditional Adversarial Networks&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Andrew presented on a CVPR 2017 paper by Isola et al. This paper aimed to investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. The networks in question were 
&lt;a href=&#34;https://arxiv.org/abs/1411.1784&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CGANs&lt;/a&gt;, proposed earlier by Mirza et al. Isola et al. also proposed the 
&lt;a href=&#34;https://paperswithcode.com/method/patchgan&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PatchGAN&lt;/a&gt; discriminator.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;A certain forgetful lead admin forgot to record this discussion. We apologize for the inconvenience&lt;/em&gt;.&lt;/p&gt;
&lt;h3 id=&#34;supplemental-resources&#34;&gt;Supplemental Resources&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Paper(s)&lt;/strong&gt;:&lt;br&gt;

&lt;a href=&#34;https://arxiv.org/abs/1611.07004&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Image-to-Image Translation with Conditional Adversarial Networks&lt;/a&gt;&lt;br&gt;

&lt;a href=&#34;https://arxiv.org/abs/1411.1784&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CGAN&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Other&lt;/strong&gt;:&lt;br&gt;

&lt;a href=&#34;https://paperswithcode.com/method/patchgan&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PatchGAN&lt;/a&gt;&lt;br&gt;

&lt;a href=&#34;https://phillipi.github.io/pix2pix/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pix2pix GitHub Page&lt;/a&gt;&lt;br&gt;

&lt;a href=&#34;https://towardsdatascience.com/gan-pix2pix-generative-model-c9bf5d691bac&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Medium article on pix2pix&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
